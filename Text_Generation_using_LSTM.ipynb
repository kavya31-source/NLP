{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Problem Statement:","metadata":{}},{"cell_type":"markdown","source":"To build an LSTM model that predicts words which falls after the end of a sentence .i.e. generates the words which are likely to appear next for a given sentence.This project considers Donald Trump's Rally Speeches for the purpose of Text generation.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-12T07:03:05.829848Z","iopub.execute_input":"2021-07-12T07:03:05.830358Z","iopub.status.idle":"2021-07-12T07:03:05.845073Z","shell.execute_reply.started":"2021-07-12T07:03:05.830251Z","shell.execute_reply":"2021-07-12T07:03:05.843773Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Import Required Libraries:","metadata":{}},{"cell_type":"code","source":"import glob\nimport numpy as np\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom sklearn.utils import shuffle\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM,Embedding,Dense,Dropout\nimport matplotlib.pyplot as plt\nimport random","metadata":{"execution":{"iopub.status.busy":"2021-07-12T11:42:13.043956Z","iopub.execute_input":"2021-07-12T11:42:13.044340Z","iopub.status.idle":"2021-07-12T11:42:13.051672Z","shell.execute_reply.started":"2021-07-12T11:42:13.044309Z","shell.execute_reply":"2021-07-12T11:42:13.050027Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"markdown","source":"## Reading the data files:","metadata":{}},{"cell_type":"code","source":"file_list=glob.glob('../input/donald-trumps-rallies/*.txt')\nlen(file_list)    # There are total 35 text files","metadata":{"execution":{"iopub.status.busy":"2021-07-12T07:26:46.185414Z","iopub.execute_input":"2021-07-12T07:26:46.185804Z","iopub.status.idle":"2021-07-12T07:26:46.195806Z","shell.execute_reply.started":"2021-07-12T07:26:46.185754Z","shell.execute_reply":"2021-07-12T07:26:46.194188Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"35"},"metadata":{}}]},{"cell_type":"code","source":"# Reading each text file and apppending them into a list\ntext=[]\nfor file in file_list:\n    with open(file,'r') as file:\n        text.append(file.read())\ntext[0][:201]","metadata":{"execution":{"iopub.status.busy":"2021-07-12T07:31:55.723136Z","iopub.execute_input":"2021-07-12T07:31:55.723523Z","iopub.status.idle":"2021-07-12T07:31:55.864118Z","shell.execute_reply.started":"2021-07-12T07:31:55.723482Z","shell.execute_reply":"2021-07-12T07:31:55.862829Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"\" Thank you very much everybody. Thank you. Wow. I will never, ever let you down, that I can tell you. Amazing. And I want to thank Manchester and New Hampshire, they're very special. You remember those\""},"metadata":{}}]},{"cell_type":"markdown","source":"## Text Pre-processing:","metadata":{}},{"cell_type":"code","source":"# The tokenizer is used to remove special characters,lower case all the remaining characters and split the sentences to words\ntokenizer=Tokenizer()\n\n# Fitting the tokenizer on the text to perform the necessary pre-processing\ntokenizer.fit_on_texts(text)\n\n#Gives the index of each word\nword_text=tokenizer.word_index\n\n#Reverses the above function\nidx_text=tokenizer.index_word\n\n# Frequency of each unique word\nword_count=tokenizer.word_counts\n\n# Total number of unique words\ntot_text=len(word_count)\ntot_text","metadata":{"execution":{"iopub.status.busy":"2021-07-12T07:41:58.305936Z","iopub.execute_input":"2021-07-12T07:41:58.306295Z","iopub.status.idle":"2021-07-12T07:41:58.726037Z","shell.execute_reply.started":"2021-07-12T07:41:58.306264Z","shell.execute_reply":"2021-07-12T07:41:58.724687Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"9176"},"metadata":{}}]},{"cell_type":"markdown","source":"## Building the Features and labels :","metadata":{}},{"cell_type":"code","source":"# Converts each of the sentence to a list of the corresponding index of each word\nseq=tokenizer.texts_to_sequences(text)\nseq[0][:10]","metadata":{"execution":{"iopub.status.busy":"2021-07-12T07:58:37.004700Z","iopub.execute_input":"2021-07-12T07:58:37.005219Z","iopub.status.idle":"2021-07-12T07:58:37.392084Z","shell.execute_reply.started":"2021-07-12T07:58:37.005188Z","shell.execute_reply":"2021-07-12T07:58:37.390925Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"[67, 5, 48, 100, 227, 67, 5, 1106, 6, 47]"},"metadata":{}}]},{"cell_type":"code","source":"# The 20 words from a sentence forms the feature and the next word i.e the 21st word forms the label.\nfeatures=[]\nlabels=[]\n\nfor s in seq:\n    for i in range(0,500):\n     \n        # Obtaining lists of 20 words\n        extract=s[i:i+20]\n        features.append(extract[:-1])\n        labels.append(extract[-1])","metadata":{"execution":{"iopub.status.busy":"2021-07-12T08:03:01.812193Z","iopub.execute_input":"2021-07-12T08:03:01.812710Z","iopub.status.idle":"2021-07-12T08:03:02.161283Z","shell.execute_reply.started":"2021-07-12T08:03:01.812678Z","shell.execute_reply":"2021-07-12T08:03:02.160042Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# Shuffling the order for better training\nfeatures,labels=shuffle(features,labels,random_state=10)\n\n#75% data will be considered for training\ntrain_end=int(len(labels)*0.75)\n\n#Independent data\ntrain_feat=features[:train_end]\ntest_feat=features[train_end:]\n\n#Dependent data\ntrain_lab=labels[:train_end]\ntest_lab=labels[train_end:]\n\n#Converting the lists to numpy arrays\nX_train=np.array(train_feat)\nX_test=np.array(test_feat)\n\n#Encoding the dependent variable\ny_train = np.zeros((len(train_lab), tot_text), dtype=np.int8)\ny_test = np.zeros((len(test_lab), tot_text), dtype=np.int8)\n\nfor example_index, word_index in enumerate(train_lab):\n    y_train[example_index, word_index] = 1\n\nfor example_index, word_index in enumerate(test_lab):\n    y_test[example_index, word_index] = 1","metadata":{"execution":{"iopub.status.busy":"2021-07-12T08:46:31.814995Z","iopub.execute_input":"2021-07-12T08:46:31.815470Z","iopub.status.idle":"2021-07-12T08:46:31.975531Z","shell.execute_reply.started":"2021-07-12T08:46:31.815439Z","shell.execute_reply":"2021-07-12T08:46:31.974253Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"# Example\nprint(\"Input:\",' '.join([idx_text[i] for i in X_train[1]]))\nprint(\"Label:\",' '.join([idx_text[train_lab[1]]]))","metadata":{"execution":{"iopub.status.busy":"2021-07-12T08:46:34.555575Z","iopub.execute_input":"2021-07-12T08:46:34.556044Z","iopub.status.idle":"2021-07-12T08:46:34.567498Z","shell.execute_reply.started":"2021-07-12T08:46:34.556013Z","shell.execute_reply":"2021-07-12T08:46:34.566212Z"},"trusted":true},"execution_count":124,"outputs":[{"name":"stdout","text":"Input: deal whether it will be no energy almost of any kind no it's crazy thought of by aoc plus\nLabel: three\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Building an LSTM model:","metadata":{}},{"cell_type":"code","source":"#Initialising the model\nmodel=Sequential()\n\n#Adding an Embedding layer with input as total number of texts\nmodel.add(Embedding(input_dim=tot_text,output_dim=100,trainable=True))\n\n#Adding the LSTM layer\nmodel.add(LSTM(128, return_sequences=False, dropout=0.1, recurrent_dropout=0.1, activation='tanh'))\n\n#Flattening \nmodel.add(Dense(64,activation='relu'))\n#Adding a dropout layer\nmodel.add(Dropout(0.5))\n#Output Layer\nmodel.add(Dense(tot_text, activation='softmax'))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-12T10:14:23.285444Z","iopub.execute_input":"2021-07-12T10:14:23.286088Z","iopub.status.idle":"2021-07-12T10:14:23.494835Z","shell.execute_reply.started":"2021-07-12T10:14:23.286025Z","shell.execute_reply":"2021-07-12T10:14:23.493756Z"},"trusted":true},"execution_count":140,"outputs":[{"name":"stdout","text":"Model: \"sequential_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_6 (Embedding)      (None, None, 100)         917600    \n_________________________________________________________________\nlstm_6 (LSTM)                (None, 128)               117248    \n_________________________________________________________________\ndense_11 (Dense)             (None, 64)                8256      \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 64)                0         \n_________________________________________________________________\ndense_12 (Dense)             (None, 9176)              596440    \n=================================================================\nTotal params: 1,639,544\nTrainable params: 1,639,544\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Compiling the Model:","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-07-12T10:14:26.694834Z","iopub.execute_input":"2021-07-12T10:14:26.695277Z","iopub.status.idle":"2021-07-12T10:14:26.710968Z","shell.execute_reply.started":"2021-07-12T10:14:26.695246Z","shell.execute_reply":"2021-07-12T10:14:26.709727Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"markdown","source":"## Fitting the Model on Train data:","metadata":{}},{"cell_type":"code","source":"my_model=model.fit(x=X_train,y=y_train,epochs=200,batch_size=128,validation_data=(X_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2021-07-12T10:14:30.179340Z","iopub.execute_input":"2021-07-12T10:14:30.179726Z","iopub.status.idle":"2021-07-12T11:03:32.521272Z","shell.execute_reply.started":"2021-07-12T10:14:30.179694Z","shell.execute_reply":"2021-07-12T11:03:32.520138Z"},"trusted":true},"execution_count":142,"outputs":[{"name":"stdout","text":"Epoch 1/200\n103/103 [==============================] - 17s 141ms/step - loss: 7.9996 - accuracy: 0.0245 - val_loss: 6.3678 - val_accuracy: 0.0434\nEpoch 2/200\n103/103 [==============================] - 15s 149ms/step - loss: 6.2210 - accuracy: 0.0435 - val_loss: 6.2955 - val_accuracy: 0.0434\nEpoch 3/200\n103/103 [==============================] - 14s 140ms/step - loss: 6.0668 - accuracy: 0.0408 - val_loss: 6.2771 - val_accuracy: 0.0434\nEpoch 4/200\n103/103 [==============================] - 15s 145ms/step - loss: 5.9991 - accuracy: 0.0348 - val_loss: 6.3051 - val_accuracy: 0.0434\nEpoch 5/200\n103/103 [==============================] - 15s 140ms/step - loss: 5.9531 - accuracy: 0.0439 - val_loss: 6.3078 - val_accuracy: 0.0533\nEpoch 6/200\n103/103 [==============================] - 15s 146ms/step - loss: 5.9310 - accuracy: 0.0436 - val_loss: 6.3098 - val_accuracy: 0.0503\nEpoch 7/200\n103/103 [==============================] - 15s 144ms/step - loss: 5.8579 - accuracy: 0.0516 - val_loss: 6.3102 - val_accuracy: 0.0503\nEpoch 8/200\n103/103 [==============================] - 15s 145ms/step - loss: 5.8206 - accuracy: 0.0537 - val_loss: 6.3069 - val_accuracy: 0.0521\nEpoch 9/200\n103/103 [==============================] - 15s 142ms/step - loss: 5.7659 - accuracy: 0.0546 - val_loss: 6.2984 - val_accuracy: 0.0542\nEpoch 10/200\n103/103 [==============================] - 15s 144ms/step - loss: 5.7227 - accuracy: 0.0531 - val_loss: 6.2931 - val_accuracy: 0.0558\nEpoch 11/200\n103/103 [==============================] - 15s 146ms/step - loss: 5.6093 - accuracy: 0.0645 - val_loss: 6.2972 - val_accuracy: 0.0638\nEpoch 12/200\n103/103 [==============================] - 14s 139ms/step - loss: 5.5646 - accuracy: 0.0676 - val_loss: 6.2327 - val_accuracy: 0.0706\nEpoch 13/200\n103/103 [==============================] - 15s 147ms/step - loss: 5.4947 - accuracy: 0.0762 - val_loss: 6.2790 - val_accuracy: 0.0729\nEpoch 14/200\n103/103 [==============================] - 14s 139ms/step - loss: 5.4294 - accuracy: 0.0843 - val_loss: 6.3140 - val_accuracy: 0.0741\nEpoch 15/200\n103/103 [==============================] - 15s 146ms/step - loss: 5.4110 - accuracy: 0.0854 - val_loss: 6.3476 - val_accuracy: 0.0784\nEpoch 16/200\n103/103 [==============================] - 15s 144ms/step - loss: 5.3941 - accuracy: 0.0875 - val_loss: 6.3298 - val_accuracy: 0.0880\nEpoch 17/200\n103/103 [==============================] - 15s 145ms/step - loss: 5.2818 - accuracy: 0.0957 - val_loss: 6.3391 - val_accuracy: 0.0914\nEpoch 18/200\n103/103 [==============================] - 14s 138ms/step - loss: 5.2690 - accuracy: 0.0956 - val_loss: 6.3767 - val_accuracy: 0.0903\nEpoch 19/200\n103/103 [==============================] - 15s 142ms/step - loss: 5.2245 - accuracy: 0.0984 - val_loss: 6.3622 - val_accuracy: 0.0935\nEpoch 20/200\n103/103 [==============================] - 15s 147ms/step - loss: 5.2103 - accuracy: 0.1030 - val_loss: 6.4178 - val_accuracy: 0.0919\nEpoch 21/200\n103/103 [==============================] - 14s 140ms/step - loss: 5.1672 - accuracy: 0.1055 - val_loss: 6.4089 - val_accuracy: 0.0944\nEpoch 22/200\n103/103 [==============================] - 15s 149ms/step - loss: 5.1341 - accuracy: 0.1087 - val_loss: 6.3761 - val_accuracy: 0.0949\nEpoch 23/200\n103/103 [==============================] - 14s 141ms/step - loss: 5.0683 - accuracy: 0.1140 - val_loss: 6.3953 - val_accuracy: 0.0955\nEpoch 24/200\n103/103 [==============================] - 15s 143ms/step - loss: 5.0430 - accuracy: 0.1117 - val_loss: 6.4474 - val_accuracy: 0.0978\nEpoch 25/200\n103/103 [==============================] - 15s 146ms/step - loss: 4.9880 - accuracy: 0.1133 - val_loss: 6.4611 - val_accuracy: 0.0965\nEpoch 26/200\n103/103 [==============================] - 15s 143ms/step - loss: 4.9636 - accuracy: 0.1146 - val_loss: 6.4381 - val_accuracy: 0.1024\nEpoch 27/200\n103/103 [==============================] - 14s 140ms/step - loss: 4.9214 - accuracy: 0.1217 - val_loss: 6.5211 - val_accuracy: 0.0990\nEpoch 28/200\n103/103 [==============================] - 15s 143ms/step - loss: 4.8825 - accuracy: 0.1202 - val_loss: 6.5306 - val_accuracy: 0.1058\nEpoch 29/200\n103/103 [==============================] - 15s 144ms/step - loss: 4.8261 - accuracy: 0.1242 - val_loss: 6.5611 - val_accuracy: 0.1070\nEpoch 30/200\n103/103 [==============================] - 15s 141ms/step - loss: 4.8026 - accuracy: 0.1251 - val_loss: 6.6360 - val_accuracy: 0.1106\nEpoch 31/200\n103/103 [==============================] - 15s 151ms/step - loss: 4.8022 - accuracy: 0.1283 - val_loss: 6.5442 - val_accuracy: 0.1106\nEpoch 32/200\n103/103 [==============================] - 14s 137ms/step - loss: 4.7177 - accuracy: 0.1328 - val_loss: 6.5933 - val_accuracy: 0.1163\nEpoch 33/200\n103/103 [==============================] - 15s 146ms/step - loss: 4.6760 - accuracy: 0.1305 - val_loss: 6.5743 - val_accuracy: 0.1227\nEpoch 34/200\n103/103 [==============================] - 15s 145ms/step - loss: 4.6524 - accuracy: 0.1401 - val_loss: 6.6828 - val_accuracy: 0.1184\nEpoch 35/200\n103/103 [==============================] - 15s 146ms/step - loss: 4.6104 - accuracy: 0.1420 - val_loss: 6.7160 - val_accuracy: 0.1202\nEpoch 36/200\n103/103 [==============================] - 14s 141ms/step - loss: 4.5523 - accuracy: 0.1422 - val_loss: 6.6965 - val_accuracy: 0.1234\nEpoch 37/200\n103/103 [==============================] - 15s 147ms/step - loss: 4.5022 - accuracy: 0.1500 - val_loss: 6.7826 - val_accuracy: 0.1287\nEpoch 38/200\n103/103 [==============================] - 14s 140ms/step - loss: 4.4587 - accuracy: 0.1575 - val_loss: 6.7557 - val_accuracy: 0.1264\nEpoch 39/200\n103/103 [==============================] - 15s 141ms/step - loss: 4.4427 - accuracy: 0.1497 - val_loss: 6.7701 - val_accuracy: 0.1250\nEpoch 40/200\n103/103 [==============================] - 15s 148ms/step - loss: 4.3777 - accuracy: 0.1600 - val_loss: 6.8387 - val_accuracy: 0.1321\nEpoch 41/200\n103/103 [==============================] - 14s 139ms/step - loss: 4.3962 - accuracy: 0.1554 - val_loss: 6.8902 - val_accuracy: 0.1355\nEpoch 42/200\n103/103 [==============================] - 15s 150ms/step - loss: 4.3110 - accuracy: 0.1659 - val_loss: 6.8460 - val_accuracy: 0.1326\nEpoch 43/200\n103/103 [==============================] - 15s 141ms/step - loss: 4.2795 - accuracy: 0.1696 - val_loss: 6.9506 - val_accuracy: 0.1371\nEpoch 44/200\n103/103 [==============================] - 15s 142ms/step - loss: 4.2742 - accuracy: 0.1627 - val_loss: 6.9854 - val_accuracy: 0.1344\nEpoch 45/200\n103/103 [==============================] - 15s 147ms/step - loss: 4.2332 - accuracy: 0.1689 - val_loss: 7.0085 - val_accuracy: 0.1394\nEpoch 46/200\n103/103 [==============================] - 14s 137ms/step - loss: 4.1788 - accuracy: 0.1718 - val_loss: 7.0269 - val_accuracy: 0.1349\nEpoch 47/200\n103/103 [==============================] - 15s 145ms/step - loss: 4.1802 - accuracy: 0.1704 - val_loss: 7.1615 - val_accuracy: 0.1397\nEpoch 48/200\n103/103 [==============================] - 15s 143ms/step - loss: 4.1488 - accuracy: 0.1758 - val_loss: 7.1895 - val_accuracy: 0.1385\nEpoch 49/200\n103/103 [==============================] - 15s 145ms/step - loss: 4.0972 - accuracy: 0.1851 - val_loss: 7.1634 - val_accuracy: 0.1401\nEpoch 50/200\n103/103 [==============================] - 14s 139ms/step - loss: 4.0401 - accuracy: 0.1877 - val_loss: 7.2259 - val_accuracy: 0.1381\nEpoch 51/200\n103/103 [==============================] - 15s 149ms/step - loss: 4.0720 - accuracy: 0.1817 - val_loss: 7.3812 - val_accuracy: 0.1463\nEpoch 52/200\n103/103 [==============================] - 14s 140ms/step - loss: 4.0317 - accuracy: 0.1787 - val_loss: 7.2929 - val_accuracy: 0.1451\nEpoch 53/200\n103/103 [==============================] - 14s 140ms/step - loss: 3.9721 - accuracy: 0.1893 - val_loss: 7.3651 - val_accuracy: 0.1454\nEpoch 54/200\n103/103 [==============================] - 15s 149ms/step - loss: 3.9768 - accuracy: 0.1916 - val_loss: 7.3923 - val_accuracy: 0.1486\nEpoch 55/200\n103/103 [==============================] - 15s 144ms/step - loss: 3.9458 - accuracy: 0.1898 - val_loss: 7.4255 - val_accuracy: 0.1458\nEpoch 56/200\n103/103 [==============================] - 15s 147ms/step - loss: 3.8826 - accuracy: 0.2050 - val_loss: 7.4352 - val_accuracy: 0.1461\nEpoch 57/200\n103/103 [==============================] - 15s 146ms/step - loss: 3.8898 - accuracy: 0.2003 - val_loss: 7.5880 - val_accuracy: 0.1479\nEpoch 58/200\n103/103 [==============================] - 15s 147ms/step - loss: 3.8438 - accuracy: 0.1972 - val_loss: 7.5496 - val_accuracy: 0.1458\nEpoch 59/200\n103/103 [==============================] - 14s 141ms/step - loss: 3.8526 - accuracy: 0.1989 - val_loss: 7.6233 - val_accuracy: 0.1479\nEpoch 60/200\n103/103 [==============================] - 15s 149ms/step - loss: 3.7704 - accuracy: 0.2094 - val_loss: 7.6778 - val_accuracy: 0.1506\nEpoch 61/200\n103/103 [==============================] - 14s 139ms/step - loss: 3.7802 - accuracy: 0.2069 - val_loss: 7.7185 - val_accuracy: 0.1479\nEpoch 62/200\n103/103 [==============================] - 14s 141ms/step - loss: 3.7671 - accuracy: 0.2092 - val_loss: 7.7861 - val_accuracy: 0.1495\nEpoch 63/200\n103/103 [==============================] - 15s 149ms/step - loss: 3.7055 - accuracy: 0.2144 - val_loss: 7.7837 - val_accuracy: 0.1529\nEpoch 64/200\n103/103 [==============================] - 14s 138ms/step - loss: 3.7218 - accuracy: 0.2096 - val_loss: 7.9253 - val_accuracy: 0.1515\nEpoch 65/200\n103/103 [==============================] - 15s 148ms/step - loss: 3.7037 - accuracy: 0.2185 - val_loss: 7.9736 - val_accuracy: 0.1529\nEpoch 66/200\n103/103 [==============================] - 14s 137ms/step - loss: 3.6439 - accuracy: 0.2263 - val_loss: 8.0246 - val_accuracy: 0.1557\nEpoch 67/200\n103/103 [==============================] - 15s 144ms/step - loss: 3.6822 - accuracy: 0.2181 - val_loss: 8.0825 - val_accuracy: 0.1527\nEpoch 68/200\n103/103 [==============================] - 15s 143ms/step - loss: 3.6073 - accuracy: 0.2300 - val_loss: 8.0652 - val_accuracy: 0.1520\nEpoch 69/200\n103/103 [==============================] - 15s 147ms/step - loss: 3.6186 - accuracy: 0.2237 - val_loss: 8.1638 - val_accuracy: 0.1504\nEpoch 70/200\n103/103 [==============================] - 14s 139ms/step - loss: 3.5843 - accuracy: 0.2228 - val_loss: 8.2558 - val_accuracy: 0.1529\nEpoch 71/200\n103/103 [==============================] - 15s 142ms/step - loss: 3.5414 - accuracy: 0.2309 - val_loss: 8.3576 - val_accuracy: 0.1536\nEpoch 72/200\n103/103 [==============================] - 15s 143ms/step - loss: 3.5372 - accuracy: 0.2324 - val_loss: 8.2845 - val_accuracy: 0.1529\nEpoch 73/200\n103/103 [==============================] - 14s 138ms/step - loss: 3.5029 - accuracy: 0.2397 - val_loss: 8.4914 - val_accuracy: 0.1538\nEpoch 74/200\n103/103 [==============================] - 15s 148ms/step - loss: 3.4826 - accuracy: 0.2410 - val_loss: 8.3758 - val_accuracy: 0.1586\nEpoch 75/200\n103/103 [==============================] - 14s 140ms/step - loss: 3.5013 - accuracy: 0.2383 - val_loss: 8.5909 - val_accuracy: 0.1559\nEpoch 76/200\n103/103 [==============================] - 15s 145ms/step - loss: 3.4445 - accuracy: 0.2425 - val_loss: 8.5623 - val_accuracy: 0.1497\nEpoch 77/200\n103/103 [==============================] - 15s 144ms/step - loss: 3.4572 - accuracy: 0.2419 - val_loss: 8.6266 - val_accuracy: 0.1561\nEpoch 78/200\n103/103 [==============================] - 15s 148ms/step - loss: 3.4509 - accuracy: 0.2454 - val_loss: 8.6930 - val_accuracy: 0.1561\nEpoch 79/200\n103/103 [==============================] - 14s 138ms/step - loss: 3.4166 - accuracy: 0.2468 - val_loss: 8.7875 - val_accuracy: 0.1595\nEpoch 80/200\n103/103 [==============================] - 15s 150ms/step - loss: 3.3876 - accuracy: 0.2499 - val_loss: 8.7709 - val_accuracy: 0.1595\nEpoch 81/200\n103/103 [==============================] - 14s 137ms/step - loss: 3.3793 - accuracy: 0.2488 - val_loss: 8.8809 - val_accuracy: 0.1611\nEpoch 82/200\n103/103 [==============================] - 14s 139ms/step - loss: 3.3838 - accuracy: 0.2479 - val_loss: 8.9143 - val_accuracy: 0.1577\nEpoch 83/200\n103/103 [==============================] - 15s 148ms/step - loss: 3.3581 - accuracy: 0.2485 - val_loss: 8.8031 - val_accuracy: 0.1609\nEpoch 84/200\n103/103 [==============================] - 15s 141ms/step - loss: 3.3116 - accuracy: 0.2638 - val_loss: 8.9987 - val_accuracy: 0.1634\nEpoch 85/200\n103/103 [==============================] - 15s 143ms/step - loss: 3.3335 - accuracy: 0.2490 - val_loss: 9.1632 - val_accuracy: 0.1618\nEpoch 86/200\n103/103 [==============================] - 15s 144ms/step - loss: 3.2881 - accuracy: 0.2554 - val_loss: 8.8931 - val_accuracy: 0.1623\nEpoch 87/200\n103/103 [==============================] - 15s 144ms/step - loss: 3.2862 - accuracy: 0.2557 - val_loss: 9.1669 - val_accuracy: 0.1625\nEpoch 88/200\n103/103 [==============================] - 14s 135ms/step - loss: 3.2490 - accuracy: 0.2667 - val_loss: 9.1214 - val_accuracy: 0.1611\nEpoch 89/200\n103/103 [==============================] - 15s 145ms/step - loss: 3.2582 - accuracy: 0.2600 - val_loss: 9.3758 - val_accuracy: 0.1579\nEpoch 90/200\n103/103 [==============================] - 14s 140ms/step - loss: 3.2134 - accuracy: 0.2690 - val_loss: 9.3763 - val_accuracy: 0.1639\nEpoch 91/200\n103/103 [==============================] - 15s 144ms/step - loss: 3.2188 - accuracy: 0.2635 - val_loss: 9.4976 - val_accuracy: 0.1609\nEpoch 92/200\n103/103 [==============================] - 15s 151ms/step - loss: 3.1773 - accuracy: 0.2736 - val_loss: 9.5803 - val_accuracy: 0.1632\nEpoch 93/200\n103/103 [==============================] - 14s 138ms/step - loss: 3.1795 - accuracy: 0.2713 - val_loss: 9.5342 - val_accuracy: 0.1607\nEpoch 94/200\n103/103 [==============================] - 15s 147ms/step - loss: 3.1845 - accuracy: 0.2757 - val_loss: 9.4255 - val_accuracy: 0.1666\nEpoch 95/200\n103/103 [==============================] - 15s 142ms/step - loss: 3.1552 - accuracy: 0.2760 - val_loss: 9.6649 - val_accuracy: 0.1643\nEpoch 96/200\n103/103 [==============================] - 15s 144ms/step - loss: 3.1700 - accuracy: 0.2798 - val_loss: 9.6282 - val_accuracy: 0.1646\nEpoch 97/200\n103/103 [==============================] - 15s 142ms/step - loss: 3.1351 - accuracy: 0.2738 - val_loss: 9.8925 - val_accuracy: 0.1650\nEpoch 98/200\n103/103 [==============================] - 15s 148ms/step - loss: 3.0951 - accuracy: 0.2859 - val_loss: 9.8723 - val_accuracy: 0.1650\nEpoch 99/200\n103/103 [==============================] - 14s 140ms/step - loss: 3.0741 - accuracy: 0.2850 - val_loss: 9.8969 - val_accuracy: 0.1637\nEpoch 100/200\n103/103 [==============================] - 14s 139ms/step - loss: 3.1137 - accuracy: 0.2791 - val_loss: 9.9787 - val_accuracy: 0.1618\nEpoch 101/200\n103/103 [==============================] - 15s 148ms/step - loss: 3.0535 - accuracy: 0.2871 - val_loss: 9.9011 - val_accuracy: 0.1646\nEpoch 102/200\n103/103 [==============================] - 14s 137ms/step - loss: 3.0533 - accuracy: 0.2877 - val_loss: 10.2324 - val_accuracy: 0.1625\nEpoch 103/200\n103/103 [==============================] - 15s 145ms/step - loss: 3.0460 - accuracy: 0.2867 - val_loss: 10.0491 - val_accuracy: 0.1630\nEpoch 104/200\n103/103 [==============================] - 14s 141ms/step - loss: 3.0104 - accuracy: 0.2946 - val_loss: 10.2405 - val_accuracy: 0.1586\nEpoch 105/200\n103/103 [==============================] - 15s 146ms/step - loss: 2.9979 - accuracy: 0.3028 - val_loss: 10.3573 - val_accuracy: 0.1627\nEpoch 106/200\n103/103 [==============================] - 14s 137ms/step - loss: 2.9745 - accuracy: 0.3058 - val_loss: 10.3902 - val_accuracy: 0.1602\nEpoch 107/200\n103/103 [==============================] - 15s 149ms/step - loss: 2.9685 - accuracy: 0.3058 - val_loss: 10.2083 - val_accuracy: 0.1657\nEpoch 108/200\n103/103 [==============================] - 14s 139ms/step - loss: 2.9977 - accuracy: 0.2973 - val_loss: 10.3279 - val_accuracy: 0.1611\nEpoch 109/200\n103/103 [==============================] - 14s 140ms/step - loss: 2.9563 - accuracy: 0.3104 - val_loss: 10.6508 - val_accuracy: 0.1614\nEpoch 110/200\n103/103 [==============================] - 15s 147ms/step - loss: 2.9322 - accuracy: 0.3136 - val_loss: 10.3916 - val_accuracy: 0.1655\nEpoch 111/200\n103/103 [==============================] - 14s 139ms/step - loss: 2.9553 - accuracy: 0.3084 - val_loss: 10.5174 - val_accuracy: 0.1634\nEpoch 112/200\n103/103 [==============================] - 15s 148ms/step - loss: 2.9034 - accuracy: 0.3111 - val_loss: 10.7740 - val_accuracy: 0.1639\nEpoch 113/200\n103/103 [==============================] - 15s 142ms/step - loss: 2.9138 - accuracy: 0.3065 - val_loss: 10.6517 - val_accuracy: 0.1648\nEpoch 114/200\n103/103 [==============================] - 15s 142ms/step - loss: 2.8957 - accuracy: 0.3114 - val_loss: 10.8565 - val_accuracy: 0.1623\nEpoch 115/200\n103/103 [==============================] - 14s 138ms/step - loss: 2.8894 - accuracy: 0.3126 - val_loss: 10.9388 - val_accuracy: 0.1655\nEpoch 116/200\n103/103 [==============================] - 15s 144ms/step - loss: 2.8698 - accuracy: 0.3117 - val_loss: 10.9712 - val_accuracy: 0.1634\nEpoch 117/200\n103/103 [==============================] - 15s 143ms/step - loss: 2.8450 - accuracy: 0.3202 - val_loss: 10.8431 - val_accuracy: 0.1641\nEpoch 118/200\n103/103 [==============================] - 14s 137ms/step - loss: 2.8742 - accuracy: 0.3193 - val_loss: 11.0218 - val_accuracy: 0.1625\nEpoch 119/200\n103/103 [==============================] - 15s 150ms/step - loss: 2.8551 - accuracy: 0.3131 - val_loss: 10.9777 - val_accuracy: 0.1643\nEpoch 120/200\n103/103 [==============================] - 14s 140ms/step - loss: 2.8368 - accuracy: 0.3110 - val_loss: 11.2124 - val_accuracy: 0.1630\nEpoch 121/200\n103/103 [==============================] - 15s 146ms/step - loss: 2.8251 - accuracy: 0.3198 - val_loss: 11.2184 - val_accuracy: 0.1650\nEpoch 122/200\n103/103 [==============================] - 15s 142ms/step - loss: 2.8087 - accuracy: 0.3187 - val_loss: 11.2844 - val_accuracy: 0.1625\nEpoch 123/200\n103/103 [==============================] - 14s 137ms/step - loss: 2.8203 - accuracy: 0.3184 - val_loss: 11.3736 - val_accuracy: 0.1623\nEpoch 124/200\n103/103 [==============================] - 15s 145ms/step - loss: 2.7954 - accuracy: 0.3312 - val_loss: 11.3604 - val_accuracy: 0.1630\nEpoch 125/200\n103/103 [==============================] - 15s 144ms/step - loss: 2.8031 - accuracy: 0.3234 - val_loss: 11.5856 - val_accuracy: 0.1662\nEpoch 126/200\n103/103 [==============================] - 15s 144ms/step - loss: 2.7813 - accuracy: 0.3220 - val_loss: 11.4709 - val_accuracy: 0.1602\nEpoch 127/200\n103/103 [==============================] - 14s 139ms/step - loss: 2.7549 - accuracy: 0.3342 - val_loss: 11.5081 - val_accuracy: 0.1637\nEpoch 128/200\n103/103 [==============================] - 15s 143ms/step - loss: 2.7518 - accuracy: 0.3242 - val_loss: 11.5405 - val_accuracy: 0.1623\nEpoch 129/200\n103/103 [==============================] - 15s 145ms/step - loss: 2.7181 - accuracy: 0.3440 - val_loss: 11.4546 - val_accuracy: 0.1630\nEpoch 130/200\n103/103 [==============================] - 14s 137ms/step - loss: 2.7356 - accuracy: 0.3344 - val_loss: 11.8071 - val_accuracy: 0.1605\nEpoch 131/200\n103/103 [==============================] - 15s 149ms/step - loss: 2.7261 - accuracy: 0.3395 - val_loss: 11.9427 - val_accuracy: 0.1643\nEpoch 132/200\n103/103 [==============================] - 14s 137ms/step - loss: 2.7169 - accuracy: 0.3415 - val_loss: 11.9050 - val_accuracy: 0.1593\nEpoch 133/200\n103/103 [==============================] - 15s 143ms/step - loss: 2.6803 - accuracy: 0.3474 - val_loss: 12.0662 - val_accuracy: 0.1600\nEpoch 134/200\n103/103 [==============================] - 14s 140ms/step - loss: 2.6760 - accuracy: 0.3511 - val_loss: 11.8778 - val_accuracy: 0.1627\nEpoch 135/200\n103/103 [==============================] - 15s 144ms/step - loss: 2.6745 - accuracy: 0.3503 - val_loss: 12.0601 - val_accuracy: 0.1602\nEpoch 136/200\n103/103 [==============================] - 14s 139ms/step - loss: 2.6500 - accuracy: 0.3473 - val_loss: 12.2091 - val_accuracy: 0.1637\nEpoch 137/200\n103/103 [==============================] - 15s 142ms/step - loss: 2.6891 - accuracy: 0.3455 - val_loss: 12.0161 - val_accuracy: 0.1618\nEpoch 138/200\n103/103 [==============================] - 15s 146ms/step - loss: 2.6508 - accuracy: 0.3512 - val_loss: 12.2055 - val_accuracy: 0.1627\nEpoch 139/200\n103/103 [==============================] - 14s 138ms/step - loss: 2.6222 - accuracy: 0.3556 - val_loss: 12.0885 - val_accuracy: 0.1605\nEpoch 140/200\n103/103 [==============================] - 15s 149ms/step - loss: 2.6287 - accuracy: 0.3565 - val_loss: 12.4646 - val_accuracy: 0.1630\nEpoch 141/200\n103/103 [==============================] - 14s 138ms/step - loss: 2.6036 - accuracy: 0.3628 - val_loss: 12.1894 - val_accuracy: 0.1584\nEpoch 142/200\n103/103 [==============================] - 15s 145ms/step - loss: 2.6276 - accuracy: 0.3501 - val_loss: 12.5292 - val_accuracy: 0.1646\nEpoch 143/200\n103/103 [==============================] - 14s 140ms/step - loss: 2.5900 - accuracy: 0.3631 - val_loss: 12.5534 - val_accuracy: 0.1634\nEpoch 144/200\n103/103 [==============================] - 15s 142ms/step - loss: 2.6038 - accuracy: 0.3562 - val_loss: 12.4044 - val_accuracy: 0.1646\nEpoch 145/200\n103/103 [==============================] - 14s 137ms/step - loss: 2.5790 - accuracy: 0.3640 - val_loss: 12.5362 - val_accuracy: 0.1637\nEpoch 146/200\n103/103 [==============================] - 15s 148ms/step - loss: 2.5691 - accuracy: 0.3675 - val_loss: 12.5657 - val_accuracy: 0.1634\nEpoch 147/200\n103/103 [==============================] - 14s 141ms/step - loss: 2.5744 - accuracy: 0.3661 - val_loss: 12.6735 - val_accuracy: 0.1609\nEpoch 148/200\n103/103 [==============================] - 14s 140ms/step - loss: 2.5715 - accuracy: 0.3592 - val_loss: 12.6664 - val_accuracy: 0.1582\nEpoch 149/200\n103/103 [==============================] - 15s 149ms/step - loss: 2.5768 - accuracy: 0.3624 - val_loss: 12.6068 - val_accuracy: 0.1600\nEpoch 150/200\n103/103 [==============================] - 14s 140ms/step - loss: 2.5712 - accuracy: 0.3593 - val_loss: 12.5824 - val_accuracy: 0.1593\nEpoch 151/200\n103/103 [==============================] - 15s 143ms/step - loss: 2.5009 - accuracy: 0.3796 - val_loss: 12.8466 - val_accuracy: 0.1600\nEpoch 152/200\n103/103 [==============================] - 14s 139ms/step - loss: 2.5308 - accuracy: 0.3671 - val_loss: 13.0057 - val_accuracy: 0.1582\nEpoch 153/200\n103/103 [==============================] - 14s 141ms/step - loss: 2.4852 - accuracy: 0.3756 - val_loss: 13.0265 - val_accuracy: 0.1630\nEpoch 154/200\n103/103 [==============================] - 15s 141ms/step - loss: 2.5041 - accuracy: 0.3788 - val_loss: 13.1911 - val_accuracy: 0.1598\nEpoch 155/200\n103/103 [==============================] - 15s 141ms/step - loss: 2.5046 - accuracy: 0.3727 - val_loss: 13.1199 - val_accuracy: 0.1607\nEpoch 156/200\n103/103 [==============================] - 15s 145ms/step - loss: 2.4575 - accuracy: 0.3804 - val_loss: 13.0548 - val_accuracy: 0.1632\nEpoch 157/200\n103/103 [==============================] - 14s 138ms/step - loss: 2.4528 - accuracy: 0.3803 - val_loss: 12.9936 - val_accuracy: 0.1671\nEpoch 158/200\n103/103 [==============================] - 15s 148ms/step - loss: 2.4678 - accuracy: 0.3827 - val_loss: 13.2261 - val_accuracy: 0.1659\nEpoch 159/200\n103/103 [==============================] - 14s 138ms/step - loss: 2.4412 - accuracy: 0.3846 - val_loss: 13.3147 - val_accuracy: 0.1614\nEpoch 160/200\n103/103 [==============================] - 15s 144ms/step - loss: 2.4284 - accuracy: 0.3896 - val_loss: 13.2832 - val_accuracy: 0.1637\nEpoch 161/200\n103/103 [==============================] - 15s 143ms/step - loss: 2.4534 - accuracy: 0.3820 - val_loss: 13.3553 - val_accuracy: 0.1666\nEpoch 162/200\n103/103 [==============================] - 15s 145ms/step - loss: 2.4366 - accuracy: 0.3794 - val_loss: 13.5109 - val_accuracy: 0.1616\nEpoch 163/200\n103/103 [==============================] - 14s 139ms/step - loss: 2.4081 - accuracy: 0.3901 - val_loss: 13.4102 - val_accuracy: 0.1643\nEpoch 164/200\n103/103 [==============================] - 15s 143ms/step - loss: 2.3924 - accuracy: 0.3991 - val_loss: 13.6581 - val_accuracy: 0.1605\nEpoch 165/200\n103/103 [==============================] - 15s 149ms/step - loss: 2.3950 - accuracy: 0.3915 - val_loss: 13.3512 - val_accuracy: 0.1643\nEpoch 166/200\n103/103 [==============================] - 14s 139ms/step - loss: 2.4242 - accuracy: 0.3860 - val_loss: 13.7734 - val_accuracy: 0.1621\nEpoch 167/200\n103/103 [==============================] - 15s 147ms/step - loss: 2.3858 - accuracy: 0.3879 - val_loss: 13.8132 - val_accuracy: 0.1643\nEpoch 168/200\n103/103 [==============================] - 14s 138ms/step - loss: 2.3767 - accuracy: 0.3948 - val_loss: 13.8604 - val_accuracy: 0.1641\nEpoch 169/200\n103/103 [==============================] - 14s 139ms/step - loss: 2.3942 - accuracy: 0.3941 - val_loss: 13.6698 - val_accuracy: 0.1605\nEpoch 170/200\n 33/103 [========>.....................] - ETA: 9s - loss: 2.4111 - accuracy: 0.3874 ","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"name":"stdout","text":"103/103 [==============================] - 14s 136ms/step - loss: 2.1611 - accuracy: 0.4332 - val_loss: 15.2764 - val_accuracy: 0.1593\nEpoch 200/200\n103/103 [==============================] - 15s 144ms/step - loss: 2.1603 - accuracy: 0.4258 - val_loss: 15.1576 - val_accuracy: 0.1653\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.plot(my_model.history['accuracy'],label='train')\nplt.plot(my_model.history['val_accuracy'],label='test')\nplt.title(\"Acuracy Comparison\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-12T11:21:00.512453Z","iopub.execute_input":"2021-07-12T11:21:00.512860Z","iopub.status.idle":"2021-07-12T11:21:00.742806Z","shell.execute_reply.started":"2021-07-12T11:21:00.512819Z","shell.execute_reply":"2021-07-12T11:21:00.741646Z"},"trusted":true},"execution_count":153,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"#### Inference:","metadata":{}},{"cell_type":"markdown","source":"- The model built gave an accuracy score of 42% on Train data and 16% on Test data.\n\n- The model clearly exhibits signs of over-fitting and high bias\n\n- One way to resolve this issue would be to increase the epochs for training the model.","metadata":{}},{"cell_type":"markdown","source":"## Generating Text (Prediction):","metadata":{}},{"cell_type":"code","source":"np.random.seed(10)\nseed=20      \nnew=20\n\n#Randomly selecting a sequence\nrand_seq=random.choice(seq)\n\n#Randomly choosing a start for the sequence\nstart_idx=random.randint(0, len(rand_seq) - seed - 5)\n\n#End point defined as 20 words after the start point\nend_idx=start_idx+seed\n\n#Slicing the start and end indexes from the randomly selected sequence\nsent=rand_seq[start_idx:end_idx]\n\n#Converting the original sequence to words\noriginal=[idx_text[i] for i in sent]\n\n#The actual list consists of the the original words in addition to 20 following words\nactual=sent[:]+rand_seq[end_idx:end_idx+new]\n\n#The list of generated words to consist of the original words in addition to 20 words predicted by the model\ngenerated=sent[:]\n\nfor i in range(new):\n    \n    #The class of the sentence is predicted\n    pred=model.predict_classes(np.array(sent).reshape(1,-1))[0]\n    new_idx=np.max(pred)\n    sent+=[new_idx]\n    generated.append(new_idx)\n\n\n\nprint(\"Original:\",\" \".join(original),\"\\n\")\nprint(\"Actual:\",\" \".join([idx_text[i]for i in actual]),\"\\n\")\nprint(\"Generated:\",\" \".join([idx_text[i]for i in generated]))","metadata":{"execution":{"iopub.status.busy":"2021-07-12T12:40:33.446964Z","iopub.execute_input":"2021-07-12T12:40:33.447362Z","iopub.status.idle":"2021-07-12T12:40:34.477357Z","shell.execute_reply.started":"2021-07-12T12:40:33.447330Z","shell.execute_reply":"2021-07-12T12:40:34.476107Z"},"trusted":true},"execution_count":256,"outputs":[{"name":"stdout","text":"Original: trump is going to go home early but it wasn't president at that time it was just donald trump he \n\nActual: trump is going to go home early but it wasn't president at that time it was just donald trump he will go home early we did that we went home early as victors but we had nine states they had \n\nGenerated: trump is going to go home early but it wasn't president at that time it was just donald trump he said why would they say sir that they say it they can't count their votes they can't count their votes\n","output_type":"stream"}]},{"cell_type":"markdown","source":" ## Conclusion:","metadata":{}},{"cell_type":"markdown","source":"- A model was built to generate the rest of the words of an in-complete sentence.\n\n- As per the example above, the model was able to generate words.However, the words generated were not accurate in comparion with the actual words of the speech.\n\n- The reason for this in-accuracy could be the low performance of the model.The model needs to be trained for much higher number of epochs.","metadata":{}}]}